{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554672af",
   "metadata": {},
   "source": [
    "# MLOps and Cloud Native AI/ML : Data ana Machine learning operationalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9f8f8",
   "metadata": {},
   "source": [
    "### Author : Oumaima Chqaf\n",
    "### Professor : Fahd Kalloubi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61bffd",
   "metadata": {},
   "source": [
    "In this notebook we will try to go over **IMDB Dataset of 5OK Movie Reviews** (*).\n",
    "We will start by preprocessing our data, then train 5 Machine Learning Models and try to track models performence, versions and parameters.\n",
    "\n",
    "(*) : You can find the notebook following this link : https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f53d3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:10.267681Z",
     "iopub.status.busy": "2023-11-12T19:26:10.267268Z",
     "iopub.status.idle": "2023-11-12T19:26:22.881250Z",
     "shell.execute_reply": "2023-11-12T19:26:22.880113Z"
    },
    "papermill": {
     "duration": 12.628934,
     "end_time": "2023-11-12T19:26:22.884009",
     "exception": false,
     "start_time": "2023-11-12T19:26:10.255075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will contain all the necessary libraries\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding,Bidirectional,LSTM,Dense,Dropout,BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , LSTM , Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bb1f5",
   "metadata": {},
   "source": [
    "### Preprocessing our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3a9b9",
   "metadata": {},
   "source": [
    "We downloaded our dataset and put it in the same file as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d65844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:22.908702Z",
     "iopub.status.busy": "2023-11-12T19:26:22.908008Z",
     "iopub.status.idle": "2023-11-12T19:26:24.237331Z",
     "shell.execute_reply": "2023-11-12T19:26:24.236325Z"
    },
    "papermill": {
     "duration": 1.344011,
     "end_time": "2023-11-12T19:26:24.239665",
     "exception": false,
     "start_time": "2023-11-12T19:26:22.895654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./IMDBDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea68dccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:24.262134Z",
     "iopub.status.busy": "2023-11-12T19:26:24.261372Z",
     "iopub.status.idle": "2023-11-12T19:26:24.276614Z",
     "shell.execute_reply": "2023-11-12T19:26:24.275703Z"
    },
    "papermill": {
     "duration": 0.028507,
     "end_time": "2023-11-12T19:26:24.278612",
     "exception": false,
     "start_time": "2023-11-12T19:26:24.250105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a79bb8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:24.300322Z",
     "iopub.status.busy": "2023-11-12T19:26:24.300065Z",
     "iopub.status.idle": "2023-11-12T19:26:24.313906Z",
     "shell.execute_reply": "2023-11-12T19:26:24.313142Z"
    },
    "papermill": {
     "duration": 0.026855,
     "end_time": "2023-11-12T19:26:24.315864",
     "exception": false,
     "start_time": "2023-11-12T19:26:24.289009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = df['review']\n",
    "target= df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55314650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:24.338044Z",
     "iopub.status.busy": "2023-11-12T19:26:24.337763Z",
     "iopub.status.idle": "2023-11-12T19:26:24.345011Z",
     "shell.execute_reply": "2023-11-12T19:26:24.344270Z"
    },
    "papermill": {
     "duration": 0.020632,
     "end_time": "2023-11-12T19:26:24.346786",
     "exception": false,
     "start_time": "2023-11-12T19:26:24.326154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d3848",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2700ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'after', 'so', 'above', 'own', 'yours', 'any', 'which', 'having', 'she', 'down', 'weren', 'her', 'their', 'what', 've', 'below', \"it's\", 'mustn', 'won', 'm', 'themselves', 'to', 'both', 'itself', 'than', 'where', 's', 'on', 'myself', 'o', 'it', 'off', 'wouldn', 'being', 'some', 'most', 'or', 'doesn', 'are', 'more', 'me', 'his', 'one', 't', 'we', 'haven', 'through', 'should', 'll', 'needn', 'does', 'from', 'its', 'the', 'under', 'just', 'them', 'shan', 'few', 'aren', 'here', 'will', 'him', 'with', 'there', 'hasn', 'because', 'is', 'as', 'yourselves', 'shouldn', 'how', 'yourself', 'against', 'until', 'of', 'all', 'ma', 'hers', 'do', 'out', 'at', 'only', 'such', 'but', 'very', 'my', 'hadn', 'can', 'while', 'i', 'these', \"that'll\", \"she's\", 'then', 'did', 'your', \"you're\", 'by', 'up', 'further', 'this', 'mightn', 'why', 'didn', 'y', 'isn', 'doing', 'same', 'was', 'our', 'were', 'those', 'himself', 'has', \"you've\", 'have', 'other', 'again', 'into', 'theirs', 'each', 'an', 'between', 'herself', 'too', 'and', 'if', 'couldn', 'be', 'in', 'for', 'he', 'they', 'about', 'once', 'over', 'before', 'had', 'whom', 'ours', 'when', \"you'd\", 'a', 'you', \"should've\", 'am', 'wasn', 'ain', 'd', 'during', \"you'll\", 'that', 'been', 'who', 'don', 'ourselves', 're'}\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "total_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# subtract negative stop words like no, not, don't etc.. from total_stopwords\n",
    "negative_stop_words = set(word for word in total_stopwords \n",
    "                          if \"n't\" in word or 'no' in word)\n",
    "\n",
    "final_stopwords = total_stopwords - negative_stop_words\n",
    "\n",
    "# \n",
    "final_stopwords.add(\"one\")\n",
    "print(final_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b786c",
   "metadata": {},
   "source": [
    "Remove unwanted words from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbde993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# ---------------------------------------------\n",
    "HTMLTAGS = re.compile('<.*?>')\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "MULTIPLE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "# ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a7f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(review):\n",
    "    # remove html tags\n",
    "    review = HTMLTAGS.sub(r'', review)\n",
    "\n",
    "    # remove puncutuation\n",
    "    review = review.translate(table)\n",
    "    \n",
    "    # remove digits\n",
    "    review = review.translate(remove_digits)\n",
    "    \n",
    "    # lower case all letters\n",
    "    review = review.lower()\n",
    "    \n",
    "    # replace multiple white spaces with single space\n",
    "    review = MULTIPLE_WHITESPACE.sub(\" \", review).strip()\n",
    "    \n",
    "    # remove stop words\n",
    "    review = [word for word in review.split()\n",
    "              if word not in final_stopwords]\n",
    "    \n",
    "    # stemming\n",
    "    review = ' '.join([stemmer.stem(word) for word in review])\n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ed4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Before preprocessing : \")\n",
    "df.review.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b0c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sure would like see resurrect date seahunt seri tech today would bring back kid excit mei grew black white tv seahunt gunsmok hero everi weekyou vote comeback new sea huntw need chang pace tv would work world water adventureoh way thank outlet like view mani viewpoint tv mani moviesso ole way believ ive got wanna saywould nice read plu point sea huntif rhyme would line would let submitor leav doubt quitif must go let'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply preprocessing function\n",
    "\n",
    "df.review = df.review.apply(preprocessor) \n",
    "print(\"After preprocessing : \")\n",
    "df.review.iloc[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd2c55a",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc28e5",
   "metadata": {},
   "source": [
    "Train set : 70% of data\n",
    "Test set : 30% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3343725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.review\n",
    "y = df.sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9ed197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000,), (10000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8788f1c",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c724e",
   "metadata": {},
   "source": [
    "Bag of Words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3b5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(max_features=10000)\n",
    "bow_vectorizer.fit(X_train)\n",
    "\n",
    "# transform\n",
    "bow_X_train = bow_vectorizer.transform(X_train)\n",
    "bow_X_test = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a2fb40",
   "metadata": {},
   "source": [
    "### Machine Lerning Model : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e2c36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "def train_and_eval(model, trainX, trainY, testX, testY):\n",
    "\n",
    "    # training\n",
    "    _ = model.fit(trainX, trainY)\n",
    "\n",
    "    # predictions\n",
    "    y_preds_train = model.predict(trainX)\n",
    "    y_preds_test = model.predict(testX)\n",
    "\n",
    "    # evaluation\n",
    "    print()\n",
    "    print(model)\n",
    "    print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\n",
    "    print(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")\n",
    "    print('\\n',40*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44b1e276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T19:26:24.368416Z",
     "iopub.status.busy": "2023-11-12T19:26:24.368145Z",
     "iopub.status.idle": "2023-11-12T19:26:24.378508Z",
     "shell.execute_reply": "2023-11-12T19:26:24.377849Z"
    },
    "papermill": {
     "duration": 0.023376,
     "end_time": "2023-11-12T19:26:24.380432",
     "exception": false,
     "start_time": "2023-11-12T19:26:24.357056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression(C=0.001, max_iter=500, random_state=1)\n",
      "Train accuracy score : 0.868725\n",
      "Test accuracy score : 0.8637\n",
      "\n",
      " ----------------------------------------\n",
      "\n",
      "LogisticRegression(C=0.01, max_iter=500, random_state=1)\n",
      "Train accuracy score : 0.905575\n",
      "Test accuracy score : 0.8851\n",
      "\n",
      " ----------------------------------------\n",
      "\n",
      "LogisticRegression(C=0.1, max_iter=500, random_state=1)\n",
      "Train accuracy score : 0.940925\n",
      "Test accuracy score : 0.8867\n",
      "\n",
      " ----------------------------------------\n",
      "\n",
      "LogisticRegression(C=1, max_iter=500, random_state=1)\n",
      "Train accuracy score : 0.969375\n",
      "Test accuracy score : 0.8723\n",
      "\n",
      " ----------------------------------------\n",
      "\n",
      "LogisticRegression(C=10, max_iter=500, random_state=1)\n",
      "Train accuracy score : 0.991325\n",
      "Test accuracy score : 0.8519\n",
      "\n",
      " ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for c in C: \n",
    "    # Define model\n",
    "    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    train_and_eval(model=log_model,\n",
    "                   trainX=bow_X_train,\n",
    "                   trainY=y_train,\n",
    "                   testX=bow_X_test,\n",
    "                   testY=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07561464",
   "metadata": {},
   "source": [
    " Best model : Logistic Regression(C=0.1) with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07cda54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=500, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmodel = LogisticRegression(C=0.1, max_iter=500, random_state=1)\n",
    "bmodel.fit(bow_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cffde5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_preds_train = bmodel.predict(bow_X_train)\n",
    "y_preds_test = bmodel.predict(bow_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a4fb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score : 0.940925\n",
      "Test accuracy score : 0.8867\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\n",
    "print(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "261d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm, annot=True, cmap='Blues', cbar=False, fmt='.2f',\n",
    "        xticklabels=target, yticklabels=target)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7ee6f",
   "metadata": {},
   "source": [
    "Let's save our model and transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "967b24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bow_vectorizer, f)\n",
    "    \n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bmodel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e0dffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Positive']\n",
    "def get_sentiment(review):\n",
    "    # preprocessing\n",
    "    x = preprocessor(review)\n",
    "    #vectorization\n",
    "    x = bow_vectorizer.transform([x])\n",
    "    #prediction\n",
    "    y = bmodel.predict(x.reshape(1,-1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9925579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a ['positive'] review!\n"
     ]
    }
   ],
   "source": [
    "# positve review\n",
    "review = \"This chips packet is very tasty. I highly recommend this!\"\n",
    "print(f\"This is a {get_sentiment(review)} review!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 653.322831,
   "end_time": "2023-11-12T19:37:00.204439",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T19:26:06.881608",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
